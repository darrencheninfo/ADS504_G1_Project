{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b59380",
   "metadata": {},
   "source": [
    "# ADS 504 Team Project\n",
    "## Evaluation & Comparison Notebook\n",
    "Author: Darren Chen & Team\n",
    "\n",
    "This notebook loads trained models and compares them using multiple evaluation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab3e20",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. Setup\n",
    "2. Load Models & Data\n",
    "3. Cross-Validation & Metrics\n",
    "4. ROC & PR Curves\n",
    "5. Calibration & Threshold Analysis\n",
    "6. Model Selection & Discussion\n",
    "7. Deployment Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ba915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 1: Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_recall_curve,\n",
    "                             roc_curve, confusion_matrix, classification_report,\n",
    "                             average_precision_score)\n",
    "import joblib, json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 2: Load Data & Models\n",
    "df = pd.read_csv('/mnt/data/diabetes_df.csv')\n",
    "TARGET = 'COMORBID'  # update if needed\n",
    "y = df[TARGET]\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "import glob, os\n",
    "model_files = glob.glob('model_*.joblib')\n",
    "models = {os.path.basename(f).split('_',1)[1].split('.joblib')[0]: joblib.load(f) for f in model_files}\n",
    "with open('model_results.json') as f:\n",
    "    base_results = json.load(f)\n",
    "print('Loaded models:', list(models.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38822f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 3: Cross-Validation & Metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import impute\n",
    "\n",
    "# Recreate preprocessor for CV\n",
    "num_cols = X.select_dtypes(include=['float64','int64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([('imp', impute.SimpleImputer(strategy='median')), ('sc', StandardScaler())]), num_cols),\n",
    "        ('cat', Pipeline([('imp', impute.SimpleImputer(strategy='most_frequent')), ('ohe', OneHotEncoder(handle_unknown='ignore'))]), cat_cols)\n",
    "    ])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics = {}\n",
    "for name, model in models.items():\n",
    "    aucs = []\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        pipe = Pipeline([('pre', preprocessor), ('model', model.steps[-1][1] if hasattr(model, 'steps') else model)])\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        y_prob = pipe.predict_proba(X_te)[:,1]\n",
    "        aucs.append(roc_auc_score(y_te, y_prob))\n",
    "    metrics[name] = {'cv_auc_mean': np.mean(aucs), 'cv_auc_std': np.std(aucs)}\n",
    "cv_df = pd.DataFrame(metrics).T.sort_values('cv_auc_mean', ascending=False)\n",
    "cv_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa21dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 4: ROC & PR Curves for Best Model\n",
    "best_model_name = cv_df.index[0]\n",
    "best_model = models[best_model_name]\n",
    "y_prob = best_model.predict_proba(X)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y, y_prob)\n",
    "precision, recall, _ = precision_recall_curve(y, y_prob)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title(f'ROC Curve ({best_model_name})')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title(f'PR Curve ({best_model_name})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 5: Calibration & Threshold Analysis\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y, y_prob, n_bins=10)\n",
    "plt.figure()\n",
    "plt.plot(prob_pred, prob_true, marker='o')\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Calibration Curve')\n",
    "plt.show()\n",
    "\n",
    "# Threshold for 90% recall\n",
    "thresholds = np.linspace(0,1,101)\n",
    "recall_vals = []\n",
    "precision_vals = []\n",
    "for t in thresholds:\n",
    "    preds = (y_prob >= t).astype(int)\n",
    "    tp = ((preds==1)&(y==1)).sum()\n",
    "    fp = ((preds==1)&(y==0)).sum()\n",
    "    fn = ((preds==0)&(y==1)).sum()\n",
    "    recall_vals.append(tp/(tp+fn))\n",
    "    precision_vals.append(tp/(tp+fp) if (tp+fp)>0 else 0)\n",
    "idx = np.argmax(np.array(recall_vals) >= 0.90)\n",
    "chosen_t = thresholds[idx]\n",
    "print(\"Chosen threshold:\", chosen_t, \"Recall:\", recall_vals[idx], \"Precision:\", precision_vals[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 6: Model Selection & Discussion\n",
    "summary = pd.concat([cv_df, pd.DataFrame(base_results).T[['acc','auc']]], axis=1)\n",
    "summary.sort_values('cv_auc_mean', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 7: Deployment Considerations\n",
    "print(\"\"\"Deployment Notes:\n",
    "- Track input data drift with statistical tests (e.g., KS test) on feature distributions.\n",
    "- Monitor performance metrics (AUC, PR AUC) on a rolling window.\n",
    "- Use shadow deployment before full rollout of retrained models.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
